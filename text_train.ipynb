{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = torch.Tensor(data)\n",
    "        self.data.to('cuda')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {'text': self.data.iloc[index][0], 'label': self.data.iloc[index][1]}\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "MULTIMODAL_SDK_PATH = \"/home/dstratton/PycharmProjects/InterpretableMultimodal/CMU-MultimodalSDK\"\n",
    "import sys\n",
    "sys.path.append(MULTIMODAL_SDK_PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import mmsdk\n",
    "from mmsdk import mmdatasdk as md\n",
    "DATASET = md.cmu_mosi\n",
    "DATA_PATH = \"cmumosi\"\n",
    "train_split = DATASET.standard_folds.standard_train_fold\n",
    "dev_split = DATASET.standard_folds.standard_valid_fold\n",
    "test_split = DATASET.standard_folds.standard_test_fold"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92m\u001B[1m[2021-12-26 20:06:23.916] | Success | \u001B[0mComputational sequence read from file cmumosi/CMU_MOSI_TimestampedWords.csd ...\n",
      "\u001B[94m\u001B[1m[2021-12-26 20:06:23.922] | Status  | \u001B[0mChecking the integrity of the <words> computational sequence ...\n",
      "\u001B[94m\u001B[1m[2021-12-26 20:06:23.922] | Status  | \u001B[0mChecking the format of the data in <words> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92m\u001B[1m[2021-12-26 20:06:23.958] | Success | \u001B[0m<words> computational sequence data in correct format.\n",
      "\u001B[94m\u001B[1m[2021-12-26 20:06:23.958] | Status  | \u001B[0mChecking the format of the metadata in <words> computational sequence ...\n",
      "\u001B[93m\u001B[1m[2021-12-26 20:06:23.958] | Warning | \u001B[0m<words> computational sequence does not have all the required metadata ... continuing \n",
      "\u001B[92m\u001B[1m[2021-12-26 20:06:23.959] | Success | \u001B[0mComputational sequence read from file cmumosi/CMU_MOSI_Opinion_Labels.csd ...\n",
      "\u001B[94m\u001B[1m[2021-12-26 20:06:23.965] | Status  | \u001B[0mChecking the integrity of the <Opinion Segment Labels> computational sequence ...\n",
      "\u001B[94m\u001B[1m[2021-12-26 20:06:23.965] | Status  | \u001B[0mChecking the format of the data in <Opinion Segment Labels> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92m\u001B[1m[2021-12-26 20:06:23.996] | Success | \u001B[0m<Opinion Segment Labels> computational sequence data in correct format.\n",
      "\u001B[94m\u001B[1m[2021-12-26 20:06:23.997] | Status  | \u001B[0mChecking the format of the metadata in <Opinion Segment Labels> computational sequence ...\n",
      "\u001B[93m\u001B[1m[2021-12-26 20:06:23.997] | Warning | \u001B[0m<Opinion Segment Labels> computational sequence does not have all the required metadata ... continuing \n",
      "\u001B[92m\u001B[1m[2021-12-26 20:06:23.997] | Success | \u001B[0mDataset initialized successfully ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "dataset = md.mmdataset({\n",
    "    'CMU_MOSI_TimestampedWords': DATA_PATH + '/CMU_MOSI_TimestampedWords.csd',\n",
    "    'CMU_MOSI_Opinion_Labels': DATA_PATH + '/CMU_MOSI_Opinion_Labels.csd'\n",
    "})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[94m\u001B[1m[2021-12-26 20:06:28.296] | Status  | \u001B[0mUnify was called ...\n",
      "\u001B[92m\u001B[1m[2021-12-26 20:06:28.296] | Success | \u001B[0mUnify completed ...\n",
      "\u001B[94m\u001B[1m[2021-12-26 20:06:28.296] | Status  | \u001B[0mPre-alignment based on <CMU_MOSI_Opinion_Labels> computational sequence started ...\n",
      "\u001B[94m\u001B[1m[2021-12-26 20:06:28.355] | Status  | \u001B[0mPre-alignment done for <CMU_MOSI_TimestampedWords> ...\n",
      "\u001B[94m\u001B[1m[2021-12-26 20:06:28.357] | Status  | \u001B[0mAlignment starting ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall Progress:   0%|          | 0/93 [00:00<?, ? Computational Sequence Entries/s]\n",
      "  0%|          | 0/13 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 03bSnISJMiM:   0%|          | 0/13 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/25 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 0h-zjBukYpk:   0%|          | 0/25 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/14 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 1DmNV9C1hbY:   0%|          | 0/14 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/30 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 1iG0909rllw:   0%|          | 0/30 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/63 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 2WGyTLYerpo:   0%|          | 0/63 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/30 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 2iD-tVS8NPw:   0%|          | 0/30 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:   6%|▋         | 6/93 [00:00<00:01, 52.99 Computational Sequence Entries/s]\n",
      "  0%|          | 0/24 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 5W7Z1C_fDaE:   0%|          | 0/24 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/12 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 6Egk_28TtTM:   0%|          | 0/12 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/14 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 6_0THN4chvY:   0%|          | 0/14 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/19 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 73jzhE8R1TQ:   0%|          | 0/19 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/39 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 7JsX8y1ysxY:   0%|          | 0/39 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/23 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 8OtFthrtaJM:   0%|          | 0/23 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/30 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 8d-gEyoeBzc:   0%|          | 0/30 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  14%|█▍        | 13/93 [00:00<00:01, 61.96 Computational Sequence Entries/s]\n",
      "  0%|          | 0/26 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 8qrpnFRGt2A:   0%|          | 0/26 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/25 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 9J25DZhivz8:   0%|          | 0/25 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/25 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 9T9Hf74oK10:   0%|          | 0/25 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/12 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 9c67fiY0wGQ:   0%|          | 0/12 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/33 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning 9qR7uwkblbs:   0%|          | 0/33 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/31 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Af8D0E4ZXaw:   0%|          | 0/31 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/31 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning BI97DNYfe5I:   0%|          | 0/31 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  22%|██▏       | 20/93 [00:00<00:01, 62.61 Computational Sequence Entries/s]\n",
      "  0%|          | 0/31 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning BXuRRbG0Ugk:   0%|          | 0/31 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/22 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Bfr499ggo-0:   0%|          | 0/22 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/30 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning BioHAh1qJAQ:   0%|          | 0/30 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/26 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning BvYR0L6f2Ig:   0%|          | 0/26 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/44 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Ci-AH39fi3Y:   0%|          | 0/44 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/31 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Clx4VXItLTE:   0%|          | 0/31 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/18 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Dg_0XKD0Mf4:   0%|          | 0/18 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  29%|██▉       | 27/93 [00:00<00:01, 60.57 Computational Sequence Entries/s]\n",
      "  0%|          | 0/21 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning G-xst2euQUc:   0%|          | 0/21 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/29 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning G6GlGvlkxAQ:   0%|          | 0/29 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/18 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning GWuJjcEuzt8:   0%|          | 0/18 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/34 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning HEsqda8_d0Q:   0%|          | 0/34 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/39 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning I5y0__X72p0:   0%|          | 0/39 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/16 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Iu2PFX3z_1s:   0%|          | 0/16 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/22 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning IumbAb8q2dM:   0%|          | 0/22 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  37%|███▋      | 34/93 [00:00<00:00, 61.75 Computational Sequence Entries/s]\n",
      "  0%|          | 0/20 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Jkswaaud0hk:   0%|          | 0/20 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/29 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning LSi-o-IrDMs:   0%|          | 0/29 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/18 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning MLal-t_vJPM:   0%|          | 0/18 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/13 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Njd1F0vZSm4:   0%|          | 0/13 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/32 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Nzq88NnDkEk:   0%|          | 0/32 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/16 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning OQvJTdtJ2H4:   0%|          | 0/16 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/24 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning OtBXNcAL_lE:   0%|          | 0/24 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/25 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Oz06ZWiO20M:   0%|          | 0/25 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  45%|████▌     | 42/93 [00:00<00:00, 64.90 Computational Sequence Entries/s]\n",
      "  0%|          | 0/13 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning POKffnXeBds:   0%|          | 0/13 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/12 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning PZ-lDQFboO8:   0%|          | 0/12 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/18 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning QN9ZIUWUXsY:   0%|          | 0/18 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/14 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Qr1Ca94K55A:   0%|          | 0/14 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/22 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Sqr0AcuoNnk:   0%|          | 0/22 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/15 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning TvyZBvOMOTc:   0%|          | 0/15 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/17 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning VCslbP0mgZI:   0%|          | 0/17 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/55 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning VbQk4H8hgr0:   0%|          | 0/55 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  54%|█████▍    | 50/93 [00:00<00:00, 65.31 Computational Sequence Entries/s]\n",
      "  0%|          | 0/9 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning Vj1wYRQjB-o:   0%|          | 0/9 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                  \u001B[A\n",
      "  0%|          | 0/32 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning W8NXH0Djyww:   0%|          | 0/32 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/22 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning WKA5OygbEKI:   0%|          | 0/22 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/11 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning X3j2zQgwYgE:   0%|          | 0/11 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/9 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning ZAIRrfG22O0:   0%|          | 0/9 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                  \u001B[A\n",
      "  0%|          | 0/34 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning ZUXBRvtny7o:   0%|          | 0/34 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/28 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning _dI--eQ6qVU:   0%|          | 0/28 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/30 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning aiEXnCPZubE:   0%|          | 0/30 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  62%|██████▏   | 58/93 [00:00<00:00, 66.77 Computational Sequence Entries/s]\n",
      "  0%|          | 0/21 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning atnd_PF-Lbs:   0%|          | 0/21 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/34 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning bOL9jKpeJRs:   0%|          | 0/34 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/25 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning bvLlb-M3UXU:   0%|          | 0/25 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/15 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning c5xsKMxpXnc:   0%|          | 0/15 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/33 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning c7UH_rxdZv4:   0%|          | 0/33 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/16 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning cM3Yna7AavY:   0%|          | 0/16 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/24 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning cW1FSBF59ik:   0%|          | 0/24 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  70%|██████▉   | 65/93 [00:01<00:00, 67.17 Computational Sequence Entries/s]\n",
      "  0%|          | 0/29 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning cXypl4FnoZo:   0%|          | 0/29 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/19 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning d3_k5Xpfmik:   0%|          | 0/19 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/43 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning d6hH302o4v8:   0%|          | 0/43 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/15 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning dq3Nf_lMPnE:   0%|          | 0/15 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/19 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning etzxEpPuc6I:   0%|          | 0/19 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/30 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning f9O3YtZ2VfI:   0%|          | 0/30 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/15 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning f_pcplsH_V0:   0%|          | 0/15 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  77%|███████▋  | 72/93 [00:01<00:00, 67.14 Computational Sequence Entries/s]\n",
      "  0%|          | 0/14 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning fvVhgmXxadc:   0%|          | 0/14 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/18 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning iiK8YX8oH1E:   0%|          | 0/18 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/27 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning jUzDDGyPkXU:   0%|          | 0/27 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/31 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning k5Y_838nuGo:   0%|          | 0/31 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/30 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning lXPQBPVc5Cw:   0%|          | 0/30 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/10 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning nbWiPyCm4g0:   0%|          | 0/10 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/24 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning nzpVDcQ0ywM:   0%|          | 0/24 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/14 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning ob23OKe5a9Q:   0%|          | 0/14 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  86%|████████▌ | 80/93 [00:01<00:00, 69.46 Computational Sequence Entries/s]\n",
      "  0%|          | 0/16 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning pLTX3ipuDJI:   0%|          | 0/16 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/21 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning phBUpBr1hSo:   0%|          | 0/21 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/22 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning rnaNMUZpvvg:   0%|          | 0/22 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/18 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning tIrG4oNLFzE:   0%|          | 0/18 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/16 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning tStelxIAHjw:   0%|          | 0/16 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/20 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning tmZoasNr4rU:   0%|          | 0/20 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/16 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning v0zCBqDeKcE:   0%|          | 0/16 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/12 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning vvZ4IcEtiZc:   0%|          | 0/12 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/22 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning vyB00TXsimI:   0%|          | 0/22 [00:00<?, ? Segments/s]\u001B[A\n",
      "Overall Progress:  96%|█████████▌| 89/93 [00:01<00:00, 73.68 Computational Sequence Entries/s]\n",
      "  0%|          | 0/30 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning wMbj6ajWbic:   0%|          | 0/30 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/24 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning yDtzw_Y-7RU:   0%|          | 0/24 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/23 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning yvsjCA6Y5Fc:   0%|          | 0/23 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                   \u001B[A\n",
      "  0%|          | 0/35 [00:00<?, ? Segments/s]\u001B[A\n",
      "Aligning zhpQhgha_KU:   0%|          | 0/35 [00:00<?, ? Segments/s]\u001B[A\n",
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92m\u001B[1m[2021-12-26 20:06:29.753] | Success | \u001B[0mAlignment to <CMU_MOSI_Opinion_Labels> complete.\n",
      "\u001B[94m\u001B[1m[2021-12-26 20:06:29.753] | Status  | \u001B[0mReplacing dataset content with aligned computational sequences\n",
      "\u001B[92m\u001B[1m[2021-12-26 20:06:29.754] | Success | \u001B[0mInitialized empty <CMU_MOSI_TimestampedWords> computational sequence.\n",
      "\u001B[94m\u001B[1m[2021-12-26 20:06:29.754] | Status  | \u001B[0mChecking the format of the data in <CMU_MOSI_TimestampedWords> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92m\u001B[1m[2021-12-26 20:06:29.757] | Success | \u001B[0m<CMU_MOSI_TimestampedWords> computational sequence data in correct format.\n",
      "\u001B[94m\u001B[1m[2021-12-26 20:06:29.757] | Status  | \u001B[0mChecking the format of the metadata in <CMU_MOSI_TimestampedWords> computational sequence ...\n",
      "\u001B[93m\u001B[1m[2021-12-26 20:06:29.757] | Warning | \u001B[0m<CMU_MOSI_TimestampedWords> computational sequence does not have all the required metadata ... continuing \n",
      "\u001B[92m\u001B[1m[2021-12-26 20:06:29.757] | Success | \u001B[0mInitialized empty <CMU_MOSI_Opinion_Labels> computational sequence.\n",
      "\u001B[94m\u001B[1m[2021-12-26 20:06:29.757] | Status  | \u001B[0mChecking the format of the data in <CMU_MOSI_Opinion_Labels> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92m\u001B[1m[2021-12-26 20:06:29.761] | Success | \u001B[0m<CMU_MOSI_Opinion_Labels> computational sequence data in correct format.\n",
      "\u001B[94m\u001B[1m[2021-12-26 20:06:29.761] | Status  | \u001B[0mChecking the format of the metadata in <CMU_MOSI_Opinion_Labels> computational sequence ...\n",
      "\u001B[93m\u001B[1m[2021-12-26 20:06:29.761] | Warning | \u001B[0m<CMU_MOSI_Opinion_Labels> computational sequence does not have all the required metadata ... continuing \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "dataset.align('CMU_MOSI_Opinion_Labels')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "segment_ids = list(dataset['CMU_MOSI_TimestampedWords'].keys())\n",
    "# filter for test set\n",
    "segment_ids = [vid for vid in segment_ids if any(substring in vid for substring in test_split)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# getting data from test set\n",
    "sentences = []\n",
    "labels = []\n",
    "for video_id in segment_ids:\n",
    "    sentence = []\n",
    "    for word in dataset['CMU_MOSI_TimestampedWords'][video_id]['features']:\n",
    "        if word[0] != b'sp':\n",
    "            sentence.append(word[0].decode('utf-8'))\n",
    "    sent = ' '.join(sentence)\n",
    "    sentences.append(sent)\n",
    "    labels.append(dataset['CMU_MOSI_Opinion_Labels'][video_id]['features'][0][0])\n",
    "    # you can also store interval information from dataset['CMU_MOSI_TimestampedWords'][video_id]['intervals'] if needed\n",
    "\n",
    "import pandas as pd\n",
    "text_data = pd.DataFrame({'text': sentences, 'labels': labels})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14140/1333508391.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  text_data['labels'][text_data['labels'] == -1] = 0\n"
     ]
    }
   ],
   "source": [
    "from datasets import ClassLabel\n",
    "import numpy as np\n",
    "text_data['labels'] = np.sign(text_data['labels']).astype('int32')\n",
    "text_data['labels'][text_data['labels'] == -1] = 0\n",
    "# ClassLabel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "data = Dataset.from_pandas(text_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "# tokenizer = transformers.AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)\n",
    "# model = transformers.AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2).cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    tens =  tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, #return_tensors=\"pt\"\n",
    "                      )\n",
    "    #tens.to('cuda')\n",
    "    return tens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d7c2c879548e4235ab12be4bffe82799"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_attempt = data.map(tokenize_function, batched=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "text_dataset = TextDataset(text_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dstratton/miniconda3/envs/InterpretableMultimodal/lib/python3.9/site-packages/torch/utils/data/datapipes/map/callable.py:55: UserWarning: Lambda function is not supported for pickle, please use regular python function or functools.partial instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer(list(text_data[\"text\"]), padding=\"max_length\", truncation=True)\n",
    "# tokenized_datasets = text_dataset.map(lambda x: tokenizer(x[\"text\"], padding=\"max_length\", truncation=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/home/dstratton/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0e7b58407f4148079d5452465209d6aa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"imdb\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/dstratton/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-55e5d530d63920d7.arrow\n",
      "Loading cached processed dataset at /home/dstratton/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-df60120efc8ea3cf.arrow\n",
      "Loading cached processed dataset at /home/dstratton/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1/cache-c9da8fb9065ff393.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "# tokenized_datasets = raw_datasets.map(tokenize_function)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\"test_trainer\", per_device_train_batch_size=2)\n",
    "# trainer = Trainer(\n",
    "#     model=model, args=training_args, train_dataset=small_train_dataset, eval_dataset=small_eval_dataset\n",
    "# )\n",
    "trainer = Trainer(\n",
    "    model=model, args=training_args, train_dataset=tokenized_attempt\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running training *****\n",
      "  Num examples = 686\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 516\n",
      "/home/dstratton/miniconda3/envs/InterpretableMultimodal/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='516' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  2/516 : < :, Epoch 0.01/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to test_trainer/checkpoint-500\n",
      "Configuration saved in test_trainer/checkpoint-500/config.json\n",
      "Model weights saved in test_trainer/checkpoint-500/pytorch_model.bin\n",
      "/home/dstratton/miniconda3/envs/InterpretableMultimodal/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=516, training_loss=0.508307181587515, metrics={'train_runtime': 98.6954, 'train_samples_per_second': 20.852, 'train_steps_per_second': 5.228, 'total_flos': 541482551930880.0, 'train_loss': 0.508307181587515, 'epoch': 3.0})"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading:   0%|          | 0.00/1.42k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5ba880a8ba114c1ca6b082752c7c6d56"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1000\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 1/63 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "{'eval_loss': 0.7528936266899109,\n 'eval_accuracy': 0.857,\n 'eval_runtime': 10.6475,\n 'eval_samples_per_second': 93.919,\n 'eval_steps_per_second': 5.917}"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.evaluate()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_8757/2875005731.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0melement\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtokenizer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mraw_datasets\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'train'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'text'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreturn_tensors\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"pt\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;31m# element.to('cuda')\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0melement\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m \u001B[0;31m# next(iter(tokenized_datasets['train']))\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/InterpretableMultimodal/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/InterpretableMultimodal/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1538\u001B[0m         \u001B[0mreturn_dict\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mreturn_dict\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mreturn_dict\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0muse_return_dict\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1539\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1540\u001B[0;31m         outputs = self.bert(\n\u001B[0m\u001B[1;32m   1541\u001B[0m             \u001B[0minput_ids\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1542\u001B[0m             \u001B[0mattention_mask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mattention_mask\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/InterpretableMultimodal/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/InterpretableMultimodal/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    990\u001B[0m         \u001B[0mhead_mask\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_head_mask\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhead_mask\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnum_hidden_layers\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    991\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 992\u001B[0;31m         embedding_output = self.embeddings(\n\u001B[0m\u001B[1;32m    993\u001B[0m             \u001B[0minput_ids\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minput_ids\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    994\u001B[0m             \u001B[0mposition_ids\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mposition_ids\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/InterpretableMultimodal/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/InterpretableMultimodal/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001B[0m\n\u001B[1;32m    212\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    213\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0minputs_embeds\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 214\u001B[0;31m             \u001B[0minputs_embeds\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mword_embeddings\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput_ids\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    215\u001B[0m         \u001B[0mtoken_type_embeddings\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtoken_type_embeddings\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtoken_type_ids\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    216\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/InterpretableMultimodal/lib/python3.9/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/InterpretableMultimodal/lib/python3.9/site-packages/torch/nn/modules/sparse.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    156\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    157\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 158\u001B[0;31m         return F.embedding(\n\u001B[0m\u001B[1;32m    159\u001B[0m             \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpadding_idx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax_norm\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    160\u001B[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001B[0;32m~/miniconda3/envs/InterpretableMultimodal/lib/python3.9/site-packages/torch/nn/functional.py\u001B[0m in \u001B[0;36membedding\u001B[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001B[0m\n\u001B[1;32m   2042\u001B[0m         \u001B[0;31m# remove once script supports set_grad_enabled\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2043\u001B[0m         \u001B[0m_no_grad_embedding_renorm_\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmax_norm\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnorm_type\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2044\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0membedding\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpadding_idx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscale_grad_by_freq\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msparse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2045\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2046\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper__index_select)"
     ]
    }
   ],
   "source": [
    "# element = next(iter(tokenized_datasets['train']))\n",
    "# del element['label']\n",
    "# del element['text']\n",
    "# next(iter(raw_datasets['train']))\n",
    "element = tokenizer(next(iter(raw_datasets['train']))['text'], return_tensors=\"pt\")\n",
    "element.to('cuda')\n",
    "model(**element)\n",
    "# next(iter(tokenized_datasets['train']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 4            |        cudaMalloc retries: 4         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |    1488 MB |    6303 MB |   36414 MB |   34925 MB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |    1488 MB |    6303 MB |   36414 MB |   34925 MB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |    6360 MB |    6370 MB |    6370 MB |   10240 KB |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |   40180 KB |  234726 KB |   12194 MB |   12154 MB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |     728    |    3721    |  306508    |  305780    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |     728    |    3721    |  306508    |  305780    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |     196    |     201    |     201    |       5    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |      20    |    1021    |  103159    |  103139    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.memory_summary(device=0, abbreviated=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}